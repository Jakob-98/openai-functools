{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintenance use case\n",
    "\n",
    "In this use-case, we create an AI assistant that helps software developers streamline the debugging process of their applications. The assistant communicates the functionalities and aids users in understanding complex system structures. It's equipped with capabilities to fetch and interpret logs, interact with databases, connect with APIs, and even query vector databases for document retrieval. The aim is to provide real-time, insightful information that supports problem-solving and makes the debugging process faster and more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from openai_functools import FunctionsOrchestrator\n",
    "from openai_functools.utils.conversation import Conversation\n",
    "\n",
    "from spoof_functions import generate_spoof_logs, generate_spoof_api_response, generate_spoof_log_analytics, generate_spoof_vector_db_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "def retrieve_logs_by_date_and_vm_id(date: str, vm_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves logs from a specific date and a specific VM.\n",
    "\n",
    "    :param str date: The date for which to retrieve the logs, formatted as \"YYYY-MM-DD\".\n",
    "    :param str vm_id: The ID of the VM for which to retrieve the logs.\n",
    "    :return: A string representing the logs of that day for the given VM.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "\n",
    "    return generate_spoof_logs(date, vm_id)\n",
    "\n",
    "\n",
    "def retrieve_log_analytics_information() -> str:\n",
    "    \"\"\"\n",
    "    Retrieves aggregate log analytics information.\n",
    "\n",
    "    :return: A string representing the summary of the logs.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "\n",
    "    return generate_spoof_log_analytics()\n",
    "\n",
    "\n",
    "def retrieve_api_information(vm_id: str, endpoint: str, params: Dict[str, Any] = None) -> str:\n",
    "    \"\"\"\n",
    "    Queries an API based on the provided endpoint and parameters.\n",
    "\n",
    "    :param str vm_id: The ID of the VM to query.\n",
    "    :param str endpoint: The endpoint of the API to query.\n",
    "    :param Dict[str, Any] params: A dictionary of parameters to include in the API query. Default is None.\n",
    "    :return: A dictionary representing the response from the API.\n",
    "    :rtype: Dict[str, Any]\n",
    "    \"\"\"\n",
    "    return generate_spoof_api_response(vm_id, endpoint, params)\n",
    "\n",
    "\n",
    "def query_vector_db(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Queries a vector database with an embedded string and returns a piece of text based on similarity.\n",
    "\n",
    "    :param str query: The string to embed and query the vector database with.\n",
    "    :return: A string representing the closest match in the vector database.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    return generate_spoof_vector_db_response(query)\n",
    "\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are an AI assistant that helps software developers streamline the debugging process of their applications.\n",
    "Your prime role is to effectively communicate the functionalities and aid users in understanding complex system structures,\n",
    "making the debugging process faster and more efficient. You're equipped with the capabilities to fetch and interpret logs,\n",
    "interact with databases, connect with APIs, and even query vector databases for document retrieval, all with an aim to provide real-time,\n",
    "insightful information that supports problem-solving. As a digital helper, you understand the intricate operations, the underlying relationships,\n",
    "and how to tap into the right resources at the right time to provide precise debugging assistance.\n",
    "Remember, your role is not only to assist but also to educate, guide, and empower the developers in their journey to make robust, high-quality software applications.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering our functions with the orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = FunctionsOrchestrator()\n",
    "orchestrator.register_all([retrieve_logs_by_date_and_vm_id, retrieve_log_analytics_information, retrieve_api_information, query_vector_db])\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", SYSTEM_MESSAGE)\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions for the maintenance app usecase\n",
    "\n",
    "FULL_LOG = []\n",
    "def call_openai(conversation: Conversation):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=conversation.conversation_history,\n",
    "        functions=orchestrator.create_function_descriptions(),\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "\n",
    "    FULL_LOG.append(response)\n",
    "    return response\n",
    "\n",
    "def handle_response(response, conversation, orchestrator):\n",
    "    # check if the response is a function call, and if so, call the function\n",
    "    # else, add the response to the conversation history and display it\n",
    "\n",
    "    if function_call := response.choices[0].message.function_call:\n",
    "        function_response = orchestrator.call_function(response)\n",
    "        conversation.add_message(role=\"function\", content=\"response from function: \" + str(function_response), function_name=function_call.name)\n",
    "        second_response = call_openai(conversation)\n",
    "        conversation.add_message(role=\"assistant\", content=second_response.choices[0].message.content)\n",
    "        handle_response(second_response, conversation, orchestrator)\n",
    "    else:\n",
    "        conversation.add_message(role=\"assistant\", content=response.choices[0].message.content)\n",
    "        conversation.display_last_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: I'm here to help! Please provide some details about the trouble you're experiencing with your application.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"Hi, I'm having trouble with my application.\")\n",
    "response = call_openai(conversation)\n",
    "handle_response(response, conversation, orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Based on the log analytics information, I found an error with the following details:\n",
      "\n",
      "VM ID: VM123\n",
      "Error Code: ERR001\n",
      "\n",
      "Please let me know if you need any further assistance with this error.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"Please check log analytics for any information on the error. Can you please provide me with the error code and the VM ID?\")\n",
    "response = call_openai(conversation)\n",
    "handle_response(response, conversation, orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Here are the logs for the error that occurred on VM123 on 2023-02-01:\n",
      "\n",
      "```\n",
      "2023-02-01 10:25:01,156 - INFO - main - Starting application\n",
      "2023-02-01 10:25:01,156 - INFO - main - Loading configuration\n",
      "2023-02-01 10:25:01,156 - INFO - main - Connecting to database\n",
      "2023-02-01 10:25:01,156 - INFO - main - Fetching data from database\n",
      "2023-02-01 10:25:01,156 - INFO - main - Data successfully fetched\n",
      "2023-02-01 10:25:01,156 - INFO - main - Starting application\n",
      "2023-02-01 10:25:01,156 - INFO - main - Loading configuration\n",
      "2023-02-01 10:25:01,156 - WARNING - main - Database connection timeout\n",
      "2023-02-01 10:25:01,156 - WARNING - main - Low disk space on server\n",
      "2023-02-01 10:25:01,156 - ERROR - main - Error loading configuration\n",
      "2023-02-01 10:25:01,156 - ERROR - component_a - Failed to initialize component - Code: ERR001\n",
      "```\n",
      "\n",
      "From the logs, it appears that the application started successfully but encountered errors during the configuration loading process. The database connection timed out, and there is also a warning about low disk space on the server. The error code ERR001 indicates a failure to initialize component_a.\n",
      "\n",
      "Let me know if you need any further assistance in debugging this issue.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"Understood.. please check the logs for more details on the error of that date, can you show me the logs?\")\n",
    "response = call_openai(conversation)\n",
    "handle_response(response, conversation, orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: I apologize, but it seems that there was an internal server error encountered when checking the health of the VM with ID VM123 at the /healthcheck endpoint. The response returned a status code of 500 and an error message of \"Internal Server Error\". The error code associated with this issue is ERR001.\n",
      "\n",
      "It appears that there is an issue with the VM, which might be the cause of the errors and warnings mentioned in the logs earlier. I recommend investigating the VM's health and resolving any underlying issues to ensure proper functioning of the application.\n",
      "\n",
      "If you need further assistance or have any additional questions, please let me know.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"Can you check if the VM is running properly? Please check the /healthcheck endpoint. Provide the full response.\")\n",
    "response = call_openai(conversation)\n",
    "handle_response(response, conversation, orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Based on the information retrieved from the vector database, the error code ERR001 indicates a critical alert for an Internal Server Error. This error typically originates from a lower-level system on the server, such as a network socket or a database connection.\n",
      "\n",
      "Here are some immediate recommended actions to address this error:\n",
      "\n",
      "1. Run a comprehensive health check on all lower-level systems to ensure they are functioning properly.\n",
      "2. Check the server's logs for any additional error messages or warnings that may provide insights into the root cause.\n",
      "3. Confirm the stability of network connections, especially those involved in inter-process communication.\n",
      "4. If you are using a database, ensure that the connections are pooling correctly and that the database is not reaching its maximum connection limit.\n",
      "5. If this error is recurring, consider profiling the server's operations to identify any potential bottlenecks or recurring issues that may be contributing to the error.\n",
      "\n",
      "If these steps do not resolve the issue, it is possible that the error is caused by an underlying bug or a hardware issue. In such cases, further investigation will be required.\n",
      "\n",
      "Let me know if you need any further clarification or assistance with this error.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"I need further help understanding the error code. Can you check the vector database to see if there is any relevant documentation?\")\n",
    "response = call_openai(conversation)\n",
    "handle_response(response, conversation, orchestrator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-functools-k4-bO2pA-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
